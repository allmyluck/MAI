{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea235ab0",
   "metadata": {},
   "source": [
    "# Лабораторная работа 2, вариант 21\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b50b4",
   "metadata": {},
   "source": [
    "\n",
    "ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ\n",
    "\n",
    "ДЕРЕВО РЕШЕНИЙ\n",
    "\n",
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9457e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-ymzdm0vs because the default path (/home/nikita/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0         0       3    0  22.0      1      0   7.2500         0\n",
       "1         1       1    1  38.0      1      0  71.2833         1\n",
       "2         1       3    1  26.0      0      0   7.9250         0\n",
       "3         1       1    1  35.0      1      0  53.1000         0\n",
       "4         0       3    0  35.0      0      0   8.0500         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "trainDataset = pd.read_csv('train_v1.csv')\n",
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625db3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, Y = trainDataset.drop(columns=['Survived']).to_numpy(), np.array(trainDataset['Survived'])\n",
    "\n",
    "#разбиваю выборку на трейн и тест. Для теста выделяю 30% выборки.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.3,random_state=42,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce75a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(y, y0):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i in range(y.shape[0]):\n",
    "        if y[i] == 0 and y0[i] == 0: tn += 1\n",
    "        if y[i] == 1 and y0[i] == 0: fn += 1\n",
    "        if y[i] == 0 and y0[i] == 1: fp += 1\n",
    "        if y[i] == 1 and y0[i] == 1: tp += 1  \n",
    "    print('Accuracy:', (tp + tn) / (tp + tn + fp + fn))\n",
    "    print('Precision:', tp / (tp + fp))\n",
    "    print('Recall:', tp / (tp + fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f865a4f2",
   "metadata": {},
   "source": [
    "# Логистическая регрессия\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca00c9f",
   "metadata": {},
   "source": [
    "В центре логистической регрессии лежит функция гипотезы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c160678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ec0613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression:\n",
    "    def __init__(self, lr, max_iter = 10000):\n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.hstack((np.full((X.shape[0], 1), 1),X))\n",
    "        weights = np.random.rand(X.shape[1])\n",
    "        for i in range(self.max_iter):\n",
    "            old_weights = weights.copy()\n",
    "            # Функция сходится к минимуму методом градиентного спуска по формуле ниже:\n",
    "            weights -= self.lr * np.dot(X.T, sigmoid(np.dot(X, weights)) - y) / len(X)\n",
    "        self.weights = weights\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.hstack((np.full((X.shape[0], 1), 1), X))\n",
    "        labels = []\n",
    "        for row in X:\n",
    "            labels.append(int(sigmoid(np.dot(row, self.weights)) > 0.5))\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "738ee97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.746268656716418\n",
      "Precision: 0.7945205479452054\n",
      "Recall: 0.5225225225225225\n"
     ]
    }
   ],
   "source": [
    "# моя реализация\n",
    "myModel = MyLogisticRegression(lr= 0.001, max_iter=10000)\n",
    "myModel.fit(Xtrain,Ytrain)\n",
    "Ypred = myModel.predict(Xtest)\n",
    "print_accuracy(Ytest, Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2f695fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8059701492537313\n",
      "Precision: 0.7920792079207921\n",
      "Recall: 0.7207207207207207\n"
     ]
    }
   ],
   "source": [
    "# реализация sklearn\n",
    "model = LogisticRegression(tol=0.001,max_iter=10000)\n",
    "model.fit(Xtrain,Ytrain)\n",
    "print_accuracy(Ytest, model.predict(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7391b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.999999999999985\n"
     ]
    }
   ],
   "source": [
    "# точность реализации sklearn выше на x %\n",
    "print((accuracy_score(Ytest, model.predict(Xtest)) / accuracy_score(Ytest, myModel.predict(Xtest)) - 1) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d9f208",
   "metadata": {},
   "source": [
    "Логистическая регрессия метод построения линейного классификатора, позволяющий оценивать апостериорные вероятности принадлежности объектов классам. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d7d35d",
   "metadata": {},
   "source": [
    "# Дерево решений и Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae53363",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Построенное вручную дерево решений просто представляет собой дерево, в каждой вершине кроме листьев в которой задается вопрос по какому-либо свойству и определяется следующая вершина в зависимости от ответа. В листьях же содержится возможная классификация на основе свойств.\n",
    "\n",
    "При построении дерева решений используется функция определения количества полученной информации, но перед её введением следует ввести формулу оценки \"загрязненности\" вершины.\n",
    "\n",
    "Вершина считается загрязненной, если (считая ее листом) в ней в качестве ответа содержится много разных классов, т.е. пройдясь по дереву классификации и дойдя до этой вершины, особенности могут быть классифицированы не одним, а двумя, тремя и более классами. Тогда вершина считается загрязненной (\"impure\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d831c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class DecisionTree:\n",
    "    class _DataPointer:\n",
    "        def __init__(self, column, value):\n",
    "            self.column = column\n",
    "            self.value  = value\n",
    "\n",
    "    class _Node:\n",
    "        def __init__(self, false_node, true_node, pointer):\n",
    "            self.false_node = false_node\n",
    "            self.true_node  = true_node\n",
    "            self.pointer    = pointer\n",
    "\n",
    "    class _Leaf:\n",
    "        def __init__(self, prediction):\n",
    "            self.prediction = prediction\n",
    "\n",
    "    def __init__(self):\n",
    "        self._root_node = None\n",
    "\n",
    "    def train(self, feats, labels):\n",
    "        self._root_node = self._build_tree(feats, labels)\n",
    "        \n",
    "    def predict(self, feats):\n",
    "        if self._root_node is None:\n",
    "            raise RuntimeError(\"Model is untrained\")\n",
    "        predicts = []\n",
    "        for feat_list in feats:\n",
    "            predicts.append(self._match(feat_list, self._root_node))\n",
    "        return predicts\n",
    "\n",
    "    def _build_tree(self, feats, labels):\n",
    "        info_gain, pointer = self._find_best_split(feats, labels)\n",
    "        if info_gain == 0:\n",
    "            return self._Leaf(np.bincount(labels).argmax())\n",
    "        false_feats, false_labels, true_feats, true_labels = self._partite(feats, labels, pointer)\n",
    "        false_node = self._build_tree(false_feats, false_labels)\n",
    "        true_node  = self._build_tree(true_feats,  true_labels)\n",
    "        return self._Node(false_node, true_node, pointer)\n",
    "\n",
    "    def _find_best_split(self, feats, labels):\n",
    "        max_info_gain = 0\n",
    "        pointer = None\n",
    "        current_impurity = self._gini(labels)\n",
    "        for col_i, col in enumerate(feats.T):\n",
    "            unique_vals = np.unique(col)\n",
    "            for u_val in unique_vals :\n",
    "                split_point = self._DataPointer(col_i, u_val)\n",
    "                _, false_labels, _, true_labels = self._partite(feats, labels, split_point)\n",
    "                if len(false_labels) == 0 or len(true_labels) == 0:\n",
    "                    continue\n",
    "                info_gain = self._info_gain(false_labels, true_labels, current_impurity)\n",
    "                if info_gain > max_info_gain:\n",
    "                    max_info_gain = info_gain\n",
    "                    pointer = split_point\n",
    "        return max_info_gain, pointer\n",
    "\n",
    "    def _partite(self, feats, labels, split_point):\n",
    "        column = split_point.column\n",
    "        value  = split_point.value\n",
    "        false_indecies = feats[:, column] <  value\n",
    "        true_indecies  = feats[:, column] >= value\n",
    "        false_feats = feats[false_indecies, :]\n",
    "        true_feats  = feats[true_indecies, :]\n",
    "        false_labels = labels[false_indecies]\n",
    "        true_labels  = labels[true_indecies]\n",
    "        return false_feats, false_labels, true_feats, true_labels\n",
    "        \n",
    "    def _match(self, feats, node):\n",
    "        if isinstance(node, self._Leaf):\n",
    "            return node.prediction\n",
    "        to_true = feats[node.pointer.column] >= node.pointer.value\n",
    "        if to_true:\n",
    "            return self._match(feats, node.true_node)\n",
    "        else:\n",
    "            return self._match(feats, node.false_node)\n",
    "\n",
    "    def _info_gain(self, false_labels, true_labels, parent_impurity):\n",
    "        false_c = len(false_labels)\n",
    "        true_c  = len(true_labels)\n",
    "        total = true_c + false_c\n",
    "        false_gini = self._gini(false_labels) * (false_c / total)\n",
    "        true_gini  = self._gini(true_labels) * (true_c / total)\n",
    "        return parent_impurity - false_gini - true_gini\n",
    "\n",
    "    def _gini(self, classes):\n",
    "        probs = np.bincount(classes) / len(classes)\n",
    "        return 1 - np.sum(probs ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "391f680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.746268656716418\n",
      "Precision: 0.7047619047619048\n",
      "Recall: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# моя реализация\n",
    "custom_tree = DecisionTree()\n",
    "custom_tree.train(Xtrain, Ytrain)\n",
    "print_accuracy(Ytest, custom_tree.predict(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b87b7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7574626865671642\n",
      "Precision: 0.7211538461538461\n",
      "Recall: 0.6756756756756757\n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "sk_tree = DecisionTreeClassifier()\n",
    "sk_tree.fit(Xtrain, Ytrain)\n",
    "\n",
    "print_accuracy(Ytest, sk_tree.predict(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17b5d214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4999999999999902\n"
     ]
    }
   ],
   "source": [
    "# точность реализации sklearn выше на x %\n",
    "print((accuracy_score(Ytest, sk_tree.predict(Xtest)) / accuracy_score(Ytest, custom_tree.predict(Xtest)) - 1) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29252c01",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a79d76",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Если не ограничивать глубину деревьев решений, то они будут стремиться максимально делить тестовые данные, в плоть до максимально чистых листьев. Random Forest стремится решить эту проблему: вместо одного дерева будет создаваться лес, причем эти деревья будет тренироваться случайно - из входных пар (Особенности, класс) $(X_1, y_1), (X_2, y_2), ..., (X_n, y_n)$ ($n$ пар) для каждого дерева будет создаваться независимая случайная выборка с заменами (пары могут повторяться многократно) и дерево будет тренироваться на ней.\n",
    "\n",
    "При обучении каждое дерево будет возвращать свой вариант классификации, после чего результатом будет наиболее частый класс (или среднее значение в случае регрессии).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdef8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees):\n",
    "        self._trees = [DecisionTree() for _ in range(n_trees)]\n",
    "\n",
    "    def train(self, feats, labels):\n",
    "        sample_size = len(feats)\n",
    "        for tree in self._trees:\n",
    "            sorted_idxs = range(sample_size)\n",
    "            sample_idxs = np.random.choice(sorted_idxs, sample_size, replace=True)\n",
    "            feats_sample = feats[sample_idxs, :]\n",
    "            labels_sample = labels[sample_idxs]\n",
    "            tree.train(feats_sample, labels_sample)\n",
    "\n",
    "    def predict(self, feats):\n",
    "        def find_most_common(row):\n",
    "            return np.bincount(row).argmax()\n",
    "        predicts = []\n",
    "        for tree in self._trees:\n",
    "            predicts.append(tree.predict(feats))\n",
    "        votes_per_sample = np.array(predicts).T\n",
    "        votes = np.apply_along_axis(find_most_common, 1, votes_per_sample)\n",
    "        return votes.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82cd4755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7761194029850746\n",
      "Precision: 0.7524752475247525\n",
      "Recall: 0.6846846846846847\n"
     ]
    }
   ],
   "source": [
    "# моя реализация\n",
    "custom_forest = RandomForest(10)\n",
    "custom_forest.train(Xtrain, Ytrain)\n",
    "print_accuracy(Ytest, custom_forest.predict(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86a77491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8059701492537313\n",
      "Precision: 0.8041237113402062\n",
      "Recall: 0.7027027027027027\n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_tree = RandomForestClassifier(10)\n",
    "rf_tree.fit(Xtrain, Ytrain)\n",
    "print_accuracy(Ytest, rf_tree.predict(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d924315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8461538461538325\n"
     ]
    }
   ],
   "source": [
    "# точность реализации sklearn выше на x %\n",
    "print((accuracy_score(Ytest, rf_tree.predict(Xtest)) / accuracy_score(Ytest, custom_forest.predict(Xtest)) - 1) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b2a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
